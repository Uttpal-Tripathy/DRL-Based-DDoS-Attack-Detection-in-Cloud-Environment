{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e105c12",
   "metadata": {},
   "source": [
    "# Cross-Dataset Evaluation Notebook\n",
    "\n",
    "This notebook reproduces the figures and tables discussed in the conversation. It is Google Colab compatible. Place your datasets in the same folder or mount Google Drive.\n",
    "\n",
    "Files generated by this notebook will be saved into `figures/` and `tables/` directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8340ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os, warnings, numpy as np, pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "!mkdir -p figures tables\n",
    "print(\"Directories created: figures/ tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3a881",
   "metadata": {},
   "source": [
    "## 1) Load datasets\n",
    "\n",
    "Place your dataset files in the notebook folder or mount Google Drive. Update the paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac41fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example placeholders for dataset paths - update if needed\n",
    "UNSW_PATH = \"UNSW-NB15_features.csv\"\n",
    "CIC_PATH  = \"cicddos2019_dataset.csv\"\n",
    "print(\"Set dataset paths. Update these paths if your files are placed elsewhere.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8e5ddc",
   "metadata": {},
   "source": [
    "## 2) Feature selection (Mutual Information + RFE)\n",
    "This cell computes mutual information and RFE and saves top feature importance figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_report(df, ycol, top_k=25, fig_name=\"figures/feature_importance.png\"):\n",
    "    X = df.drop(columns=[ycol])\n",
    "    y = df[ycol]\n",
    "    mi = mutual_info_classif(X.fillna(0), y, random_state=RANDOM_STATE)\n",
    "    mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)\n",
    "    base = LogisticRegression(max_iter=200)\n",
    "    n_features = min(30, X.shape[1]) if X.shape[1] > 30 else max(5, X.shape[1]//2)\n",
    "    selector = RFE(base, n_features_to_select=n_features, step=1)\n",
    "    selector.fit(X.fillna(0), y)\n",
    "    rfe_rank = pd.Series(selector.ranking_, index=X.columns).sort_values()\n",
    "    feat_df = pd.DataFrame({'Mutual_Info':mi_series, 'RFE_Rank': rfe_rank})\n",
    "    top = mi_series.head(top_k)\n",
    "    plt.figure(figsize=(12,7))\n",
    "    top.sort_values(ascending=True).plot(kind='barh', alpha=0.9)\n",
    "    plt.xlabel('Importance Score'); plt.title('Feature Importance (Mutual Information)')\n",
    "    plt.tight_layout(); plt.savefig(fig_name, dpi=160); plt.show()\n",
    "    feat_df.to_csv(fig_name.replace('.png','.csv').replace('figures/','tables/'))\n",
    "    return feat_df\n",
    "\n",
    "print('Feature selection helper defined. Run this after loading your numeric dataframes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669d6b5",
   "metadata": {},
   "source": [
    "## 3) Synthetic ROC curves & Figures\n",
    "\n",
    "This cell reproduces the ROC figure using the AUCs provided in the conversation (synthetic curves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_roc_from_auc(auc, n=300):\n",
    "    x = np.linspace(0,1,n)\n",
    "    a = max(1.001, 5*(auc-0.5)+1)\n",
    "    y = 1 - (1 - x**(1/a))**a\n",
    "    adj = (auc - 0.5) * 0.12\n",
    "    y = np.clip(y + adj*(1 - 2*x), 0, 1)\n",
    "    return x, y\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "models_auc = {\n",
    "    \"Naïve Bayes\": 0.8964,\n",
    "    \"Decision Tree\": 0.9244,\n",
    "    \"SVM\": 0.9412,\n",
    "    \"Random Forest\": 0.9547,\n",
    "    \"DNN\": 0.9638,\n",
    "    \"Ensemble\": 0.9656,\n",
    "    \"CNN\": 0.9683,\n",
    "    \"LSTM\": 0.9711,\n",
    "    \"A2C\": 0.9733,\n",
    "    \"DDPG\": 0.9764,\n",
    "    \"TD3\": 0.9849\n",
    "}\n",
    "for name, auc in models_auc.items():\n",
    "    fpr, tpr = synthetic_roc_from_auc(auc)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.4f})\", linewidth=2)\n",
    "plt.plot([0,1],[0,1],'k--',label='Random Classifier (AUC = 0.5)')\n",
    "plt.title('ROC Curve Comparison of All Models'); plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right', ncol=2, fontsize=9, frameon=True); plt.tight_layout()\n",
    "plt.savefig('figures/roc_curves_all_models.png', dpi=180); plt.show()\n",
    "print('Saved: figures/roc_curves_all_models.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eab6ce",
   "metadata": {},
   "source": [
    "## 4) K-Fold Accuracy bar plot (uses provided table values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7e0fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5 values (provided)\n",
    "tbl5 = pd.DataFrame({\n",
    "\"Model\":[\"Naïve Bayes\",\"Decision Tree\",\"SVM\",\"Random Forest\",\"Ensemble\",\"DNN\",\"CNN\",\"LSTM\",\"A2C\",\"DDPG\",\"TD3\"],\n",
    "\"Fold 1\":[90.98,93.10,94.00,95.60,96.72,96.10,96.55,96.92,97.30,97.75,99.00],\n",
    "\"Fold 2\":[91.22,93.42,94.35,95.80,96.95,96.25,96.70,97.05,97.45,97.88,99.10],\n",
    "\"Fold 3\":[90.85,93.50,94.25,95.90,96.88,96.40,96.82,97.15,97.55,97.90,99.15],\n",
    "\"Fold 4\":[91.10,93.20,94.10,95.65,96.74,96.30,96.60,97.00,97.40,97.80,99.20],\n",
    "\"Fold 5\":[91.35,93.48,94.35,95.90,96.90,96.35,96.75,97.10,97.40,97.92,99.15]\n",
    "})\n",
    "tbl5[\"Average Accuracy (%)\"] = tbl5[[f\"Fold {i}\" for i in range(1,6)]].mean(axis=1).round(2)\n",
    "tbl5.to_csv('tables/Table5_KFold.csv', index=False)\n",
    "tbl5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e8899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold accuracy bar plot\n",
    "fold_cols = [f\"Fold {i}\" for i in range(1,6)]\n",
    "avg_col = \"Average Accuracy (%)\"\n",
    "plt.figure(figsize=(14,7))\n",
    "x = np.arange(len(tbl5['Model']))\n",
    "width = 0.13\n",
    "for i, col in enumerate(fold_cols + [avg_col]):\n",
    "    plt.bar(x + (i-2.5)*width, tbl5[col], width, label=col)\n",
    "plt.xticks(x, tbl5['Model'], rotation=20); plt.ylim(85,100); plt.ylabel('Accuracy (%)')\n",
    "plt.title('K-Fold Cross-Validation Accuracy per Model'); plt.legend(); plt.tight_layout()\n",
    "plt.savefig('figures/kfold_accuracy_per_model.png', dpi=180); plt.show()\n",
    "print('Saved: figures/kfold_accuracy_per_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08695f2",
   "metadata": {},
   "source": [
    "## 5) Confusion matrices (use provided counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde43c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, seaborn as sns\n",
    "cms = {\n",
    "    \"Naïve Bayes\": np.array([[900,100],[100,900]]),\n",
    "    \"Decision Tree\": np.array([[924, 76],[ 76,924]]),\n",
    "    \"SVM\": np.array([[936, 64],[ 64,936]]),\n",
    "    \"Random Forest\": np.array([[950, 50],[ 50,950]]),\n",
    "    \"Ensemble\": np.array([[961, 39],[ 39,961]]),\n",
    "    \"DNN\": np.array([[963, 37],[ 37,963]]),\n",
    "    \"CNN\": np.array([[967, 33],[ 33,967]]),\n",
    "    \"LSTM\": np.array([[969, 31],[ 31,969]]),\n",
    "    \"A2C\": np.array([[967, 33],[ 33,967]]),\n",
    "    \"DDPG\": np.array([[973, 27],[ 27,973]]),\n",
    "    \"TD3\": np.array([[988, 12],[ 12,988]])\n",
    "}\n",
    "fig, axes = plt.subplots(3,4, figsize=(14,10))\n",
    "axes = axes.flatten()\n",
    "for ax, (name, cm) in zip(axes, cms.items()):\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax,\n",
    "                xticklabels=['Attack','Benign'], yticklabels=['Attack','Benign'])\n",
    "    ax.set_title(name); ax.set_xlabel('Predicted label'); ax.set_ylabel('True label')\n",
    "if len(cms) < len(axes):\n",
    "    for j in range(len(cms), len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "plt.suptitle('Confusion Matrices', y=1.02, fontsize=16); plt.tight_layout()\n",
    "plt.savefig('figures/confusion_matrices_grid.png', dpi=180, bbox_inches='tight'); plt.show()\n",
    "print('Saved: figures/confusion_matrices_grid.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d509b845",
   "metadata": {},
   "source": [
    "## 6) Tables (Scenario A & B)\n",
    "Tables are created using the exact numbers provided in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8914de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl3 = pd.DataFrame({\n",
    "    \"Model\": [\"Naïve Bayes\",\"Decision Tree\",\"SVM\",\"Random Forest\",\"Ensemble\",\"CNN\",\"DNN\",\"LSTM\",\"A2C\",\"DDPG\",\"TD3\"],\n",
    "    \"Accuracy (%)\":[88.92,91.40,92.88,94.26,95.30,96.11,95.72,96.42,96.04,96.68,98.43],\n",
    "    \"Precision (%)\":[88.30,91.05,92.45,94.35,95.42,95.85,95.40,96.10,95.95,96.55,98.21],\n",
    "    \"Recall (%)\":[87.45,90.72,92.10,93.88,95.05,95.62,95.10,95.92,95.78,96.42,98.13],\n",
    "    \"F1-Score (%)\":[87.87,90.88,92.27,94.11,95.23,95.73,95.25,96.01,95.86,96.48,98.36],\n",
    "    \"AUC (%)\":[88.50,91.78,93.40,94.82,96.02,96.40,95.88,96.65,96.75,97.12,98.11]\n",
    "})\n",
    "tbl4 = pd.DataFrame({\n",
    "    \"Model\": [\"Naïve Bayes\",\"Decision Tree\",\"SVM\",\"Random Forest\",\"Ensemble\",\"DNN\",\"CNN\",\"LSTM\",\"A2C\",\"DDPG\",\"TD3\"],\n",
    "    \"Accuracy (%)\":[91.12,93.34,94.21,95.77,96.84,96.95,97.18,97.35,97.42,97.85,99.12],\n",
    "    \"Precision (%)\":[90.45,92.97,94.55,95.98,96.75,96.62,96.90,97.02,97.30,97.71,98.86],\n",
    "    \"Recall (%)\":[89.85,92.50,93.78,95.33,96.42,96.30,96.71,96.88,97.15,97.66,99.02],\n",
    "    \"F1-Score (%)\":[90.15,92.73,94.16,95.65,96.58,96.46,96.80,96.95,97.22,97.68,98.94],\n",
    "    \"AUC (%)\":[90.78,93.10,94.83,96.12,97.10,96.88,97.25,97.56,97.91,98.15,98.87]\n",
    "})\n",
    "tbl5.to_csv('tables/Table5_KFold.csv', index=False)\n",
    "tbl3.to_csv('tables/Table3_ScenarioA.csv', index=False)\n",
    "tbl4.to_csv('tables/Table4_ScenarioB.csv', index=False)\n",
    "print('Saved tables to tables/ directory')\n",
    "tbl3.head()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
